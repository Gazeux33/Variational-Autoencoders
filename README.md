# Variational-Autoencoders(VAEs)

## The project 

This project is an implementation of Variational Autoencoders (VAEs) using PyTorch. VAEs are generative models that learn to represent high-dimensional data in a lower-dimensional latent space and can generate new data samples similar to the training data.

## Features
+ Implementation of a Variational Autoencoder architecture.
+ Training pipeline for learning latent representations.
+ Generation of new data samples from the learned latent space.
<br>




## What is a VAE ?

 <div align="center">
 <img  alt="VAE" align="center" src="https://github.com/Gazeux33/Variational-Autoencoders/blob/main/assets/VAE.png" width="500"  />
 </div>

 <br>

## Technical specifications

| Property       | Value         |
|----------------|---------------|
| Device         | MAC M2        |
| Training Time  | ~20 min       |
| Epochs         | 5             |
| Training Data  | FashionMNIST  |
| Framework      | PyTorch       |
| Learning rate  | 0.001         |





 ## Examples of constructions and reconstructions



  <div align="center">
 <img  alt="VAE" align="center" src="https://github.com/Gazeux33/Variational-Autoencoders/blob/main/assets/original_reconstruction.png" width="500"  />
 </div>

 <br>

 ## Examples of images extracted directly from latent space (fictives images)

   <div align="center">
 <img  alt="VAE" align="center" src="https://github.com/Gazeux33/Variational-Autoencoders/blob/main/assets/z_sample.png" width="500"  />
 </div>



